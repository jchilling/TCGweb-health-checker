"""
ç‚ºæ¯å€‹ç¶²ç«™è³‡æ–™å¤¾ç”¢ç”Ÿå…©å€‹CSVæª”æ¡ˆï¼š
1. error_pages.csv - å…§éƒ¨éŒ¯èª¤é é¢
2. error_external_links.csv - éŒ¯èª¤å¤–éƒ¨é€£çµ
"""

import json
import csv
from pathlib import Path

def write_to_csv(data_list, output_file):
    """å°‡çµæœå¯«å…¥CSVæª”æ¡ˆ"""
    with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:
        fieldnames = ['problematic_url', 'status', 'parent_url']
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        
        # å¯«å…¥æ¨™é¡Œè¡Œ
        writer.writeheader()
        
        # å¯«å…¥è³‡æ–™
        for item in data_list:
            writer.writerow(item)

def extract_error_links_from_json(json_file_path):
    """å¾ page_summary.json æª”æ¡ˆä¸­æå–éŒ¯èª¤é€£çµ"""
    json_path = Path(json_file_path)
    
    if not json_path.exists():
        print(f"  âš ï¸  JSON æª”æ¡ˆä¸å­˜åœ¨: {json_file_path}")
        return
    
    website_folder = json_path.parent
    
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            
        error_pages = []
        error_external_links = []
        
        # è™•ç† page_summary ä¸­çš„éŒ¯èª¤é é¢
        page_summary = data.get('page_summary', {})
        for url, link_info in page_summary.items():
            status = link_info.get('status', 200)
            
            # åªè™•ç†æœ‰å•é¡Œçš„é€£çµ (é200ç‹€æ…‹ç¢¼)
            if status != 200:
                source_page = link_info.get('source_page')
                source_page_url = source_page.get('url', '') if source_page else ''
                
                error_pages.append({
                    'problematic_url': url,
                    'status': status,
                    'parent_url': source_page_url
                })
        
        # è™•ç† external_links ä¸­çš„éŒ¯èª¤å¤–éƒ¨é€£çµ
        external_links = data.get('external_links', {})
        for url, link_info in external_links.items():
            status = link_info.get('status', 200)
            
            # åªè™•ç†æœ‰å•é¡Œçš„é€£çµ (é200ç‹€æ…‹ç¢¼)
            if status != 200:
                source_page = link_info.get('source_page')
                source_page_url = source_page.get('url', '') if source_page else ''
                
                error_external_links.append({
                    'problematic_url': url,
                    'status': status,
                    'parent_url': source_page_url
                })
        
        # å¯«å…¥CSVæª”æ¡ˆ
        if error_pages:
            error_pages_file = website_folder / "error_pages.csv"
            write_to_csv(error_pages, error_pages_file)
            print(f"  ğŸ“„ ç”¢ç”Ÿ error_pages.csv ({len(error_pages)} ç­†)")
        
        if error_external_links:
            error_external_links_file = website_folder / "error_external_links.csv"
            write_to_csv(error_external_links, error_external_links_file)
            print(f"  ğŸ“„ ç”¢ç”Ÿ error_external_links.csv ({len(error_external_links)} ç­†)")
            
        if not error_pages and not error_external_links:
            print(f"  âœ… æ²’æœ‰ç™¼ç¾éŒ¯èª¤é€£çµ")
                    
    except Exception as e:
        print(f"  âŒ æå–éŒ¯èª¤é€£çµæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")